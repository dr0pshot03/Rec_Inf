aero-tactile integration speech perception
visual information speakers face can enhance interfere accurate auditory perception integration information across auditory visual streams observed functional imaging studies typically attributed frequency robustness perceivers jointly encounter event-specific information two modalities adding tactile modality long considered crucial next step understanding multisensory integration however previous studies found influence tactile input speech perception limited circumstances either perceivers aware task received training establish cross-modal mapping- show perceivers integrate naturalistic tactile information auditory speech perception without previous training drawing observation speech sounds produce tiny bursts aspiration english p applied slight inaudible air puffs participants skin one two locations: right hand neck syllables heard simultaneously cutaneous air puffs likely heard aspirated example causing participants mishear b p results demonstrate perceivers integrate event-relevant tactile information auditory perception much way visual information
